
# ğŸ§  Medical Data ETL Pipeline

A simple **ETL (Extract, Transform, Load)** pipeline built with **Python + Pandas**, designed to clean and process a medical dataset in a fully containerized environment using **Docker** and **Docker Compose**.

---

## ğŸš€ Features

* ğŸ“¥ **Extract** â€” Reads raw medical data from a CSV file
* ğŸ”„ **Transform** â€” Cleans missing values and normalizes column names
* ğŸ“¤ **Load** â€” Saves the cleaned dataset to a new CSV file
* ğŸ³ **Dockerized** â€” Easily run the entire pipeline using Docker
* ğŸ§© **Compose Ready** â€” Includes `docker-compose.yml` for seamless orchestration

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Medicaldataset.csv
â”‚   â””â”€â”€ CleanedMedicalData.csv (generated)
â”œâ”€â”€ main.py
â””â”€â”€ README.md
```

---

## âš™ï¸ How It Works

1. **Extract:** Reads the raw dataset from `/data/Medicaldataset.csv`.
2. **Transform:**

   * Drops rows with missing values
   * Normalizes column names (lowercase + underscores)
3. **Load:** Saves the cleaned data as `/data/CleanedMedicalData.csv`.

---

## ğŸ³ Run with Docker

### 1ï¸âƒ£ Build the image

```bash
docker build -t medical-etl .
```

### 2ï¸âƒ£ Run the container

```bash
docker run -v $(pwd)/data:/data medical-etl
```

### 3ï¸âƒ£ Or use Docker Compose

```bash
docker-compose up
```

---

## âœ… Output

After running, youâ€™ll find your cleaned dataset here:

```
/data/CleanedMedicalData.csv
```

---

## ğŸ’¡ Example Logs

```
Data extraction completed  
Data transformation completed  
Data loading completed  
Data pipeline completed successfully  
```


